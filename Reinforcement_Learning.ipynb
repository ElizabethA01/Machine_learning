{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reinforcement Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMd1yeuYvFLf8Wwgg84C5X7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElizabethA01/Machine_learning/blob/main/Reinforcement_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reinforcement learning**\n",
        "\n",
        "The AI trains itself on how to play a game through trial and error to maximise the reward for the agent in an environment. \n",
        "\n",
        "Example = mario game\n",
        "\n",
        "agent = the entity that is exploring the environment e.g. character in a game\n",
        "\n",
        "environment = surrounding or level of the game\n",
        "\n",
        "state = status of the agent e.g. location of the agent \n",
        "action = interaction between agent and environment e.g. jumping \n",
        "\n",
        "reward = a reward (either positive or negative) for every action\n",
        "\n",
        "Q-learning = involves learning a matrix of action-reward values a.k.a Q-table or Q-matrix. It tells you the predicted reward for any state based on action taken.\n",
        "\n",
        "Q learning chooses its next action by either:\n",
        "randomly choosing\n",
        "\n",
        "or based on Q table"
      ],
      "metadata": {
        "id": "nGBJ-hQW51ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open AI gym project"
      ],
      "metadata": {
        "id": "H5dU9d_8BM1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym"
      ],
      "metadata": {
        "id": "odNbiySNBDZB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v0') # going to use the Frozenlake environment"
      ],
      "metadata": {
        "id": "LMc8PIoPBFV1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.observation_space.n) # get number of states\n",
        "print(env.action_space.n) # get number of actions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsAbPbHGBVy8",
        "outputId": "308fe738-94cd-4d1d-efa7-031f80eecdf2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset() # reset environment to default state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L1ZXlytBe0x",
        "outputId": "bd167450-aeea-4704-9b7f-62e54b5a827a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action = env.action_space.sample() # get a random action \n",
        "print(action)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QB8kltKBgWZ",
        "outputId": "2e4b03c0-c5a5-4ae2-8504-2b87e7161e06"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation, reward, done, info = env.step(action) # take action, notice it return information about the action"
      ],
      "metadata": {
        "id": "Yxx4jV5XBmW4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.render() #  render the GUI for the environment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uX4hjLXBxna",
        "outputId": "2853fce9-a166-4daf-db28-710f471f9ef1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Right)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Frozen Lake Environment**\n",
        "\n"
      ],
      "metadata": {
        "id": "nryHaOTzB7or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# building the Q-table\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "env = gym.make('FrozenLake-v0')\n",
        "STATES = env.observation_space.n\n",
        "ACTIONS = env.action_space.n"
      ],
      "metadata": {
        "id": "K0rWxebfB1my"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = np.zeros((STATES, ACTIONS)) # create a matrix with all 0 values\n",
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXULJZW2CX-Q",
        "outputId": "c602dcb6-6edf-4112-9de0-6a54e6dd6eaf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define some constants\n",
        "\n",
        "EPISODES = 10000 # how many time to run the environment from the beginning\n",
        "MAX_STEPS = 100 # max no. of steps allowed for each run of environment\n",
        "\n",
        "LEARNING_RATE = 0.81 # learning rate. the higher it is, the faster it runs\n",
        "GAMMA = 0.96"
      ],
      "metadata": {
        "id": "0848I24yCgk6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Picking an action\n",
        "\n",
        "epsilon = 0.9 # start with a 90% chance of picking a random action\n",
        "\n",
        "# code to pick action\n",
        "if np.random.uniform(0, 1) < epsilon: # check if a randomly selected value is less than epsilon\n",
        "  action = env.action_space.sample()\n",
        "else:\n",
        "  action = np.argmax(Q,[state, ]) # use Q table to pick best action based on current values\n"
      ],
      "metadata": {
        "id": "61ammWqlIuIt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updating Q values\n",
        "Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA + np.max(Q[new_state, ]) - Q [state, action])"
      ],
      "metadata": {
        "id": "689aFzTPJOgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RENDER = False \n",
        "\n",
        "rewards = []\n",
        "for episode in range(EPISODES):\n",
        "  state = env.reset()\n",
        "  for _ in range(MAX_STEPS):\n",
        "    \n",
        "    if RENDER:\n",
        "      env.render()\n",
        "    if np.random.uniform(0,1) < epsilon:\n",
        "      action = np.argmax(Q[state,])\n",
        "    \n",
        "    next_state, reward, done, _ = env.step(action)\n",
        "    Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA + np.max(Q[new_state, ]) - Q [state, action])\n",
        "\n",
        "    state = next_state\n",
        "\n",
        "    if done:\n",
        "      rewards.append(reward)\n",
        "      epsilon -= 0.001\n",
        "      break # reached goal\n",
        "\n",
        "print(Q)\n",
        "print(f'Average reward is: {sum(rewards)/len(rewards)}:')\n",
        "\n",
        "#and now we can see our Q values!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "MkMtArNNJ1ya",
        "outputId": "d51248e9-178f-4339-b920-79fc5b97f347"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-4b66dd095531>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'new_state' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can plot the training progres and see how the agent improved\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_average(values):\n",
        "  return sum(values)/len(values)\n",
        "\n",
        "avg_rewards = []\n",
        "for i in range(0, len(rewards), 100):\n",
        "    avg_rewards.append(get_average(rewards[i:i+100]))\n",
        "\n",
        "\n",
        "plt.plot(avg_rewards)\n",
        "plt.ylabel('average reward')\n",
        "plt.xlabel('episodes (100\\'s)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "zUUqT852LDN1",
        "outputId": "770faf97-fa0b-4d22-99d2-f5defdcc7c1d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXDElEQVR4nO3dfbRddX3n8feHpIKi5TEgEiBYqBZEUa9QxzqDBSI41aAyS7SMGavSGR/G6tiKoyMPMlNAW5TWVqnYplgLVpc1DlYaoih2GOUGn0DBRJQFCBIN4qQIiHznj72Dh+tJ7sm+99xzLvf9Wuusu/dv/87Z31/uWvnc/XB+O1WFJEnba4dRFyBJmp8MEElSJwaIJKkTA0SS1IkBIknqZPGoC5hLe+65Zy1btmzUZUjSvLJu3bofVtWSqe0LKkCWLVvG5OTkqMuQpHklyU392j2FJUnqxACRJHVigEiSOjFAJEmdGCCSpE4MEElSJwaIJKkTA0SS1IkBIknqxACRJHVigEiSOjFAJEmdGCCSpE4MEElSJwaIJKkTA0SS1IkBIknqxACRJHVigEiSOjFAJEmdGCCSpE4MEElSJwaIJKkTA0SS1IkBIknqZKQBkuS4JDck2ZDk1D7bd0xySbv9S0mWTdm+f5LNSd48VzVLkhojC5Aki4D3AccDhwAvTXLIlG6vBO6sqoOA84Bzpmz/U+Cfhl2rJOmXjfII5AhgQ1XdWFX3ARcDK6b0WQGsapc/BhydJABJTgC+C1w3R/VKknqMMkD2BW7uWb+lbevbp6ruB+4C9kjyaOAtwBnT7STJKUkmk0xu3LhxVgqXJM3fi+inA+dV1ebpOlbVBVU1UVUTS5YsGX5lkrRALB7hvm8F9utZX9q29etzS5LFwC7Aj4AjgROTnAvsCjyQ5J6q+vPhly1JgtEGyNXAwUkOpAmKk4CXTemzGlgJXAWcCHy2qgp49pYOSU4HNhsekjS3RhYgVXV/ktcBlwGLgA9V1XVJzgQmq2o1cCFwUZINwCaakJEkjYE0f9AvDBMTEzU5OTnqMiRpXkmyrqomprbP14vokqQRM0AkSZ0YIJKkTgwQSVInBogkqRMDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTgwQSVInBogkqRMDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTgwQSVInBogkqRMDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTgwQSVInBogkqRMDRJLUyUgDJMlxSW5IsiHJqX2275jkknb7l5Isa9uPTbIuyTfan78917VL0kI3sgBJsgh4H3A8cAjw0iSHTOn2SuDOqjoIOA84p23/IfD8qjoMWAlcNDdVS5K2GOURyBHAhqq6saruAy4GVkzpswJY1S5/DDg6SarqK1X1/bb9OuCRSXack6olScBoA2Rf4Oae9Vvatr59qup+4C5gjyl9XgxcU1X3DqlOSVIfi0ddwEwkOZTmtNbybfQ5BTgFYP/995+jyiTp4W+URyC3Avv1rC9t2/r2SbIY2AX4Ubu+FPgE8PKq+s7WdlJVF1TVRFVNLFmyZBbLl6SFbatHIEk+BdTWtlfVC2a476uBg5McSBMUJwEvm9JnNc1F8quAE4HPVlUl2RW4FDi1qv5lhnVIkjrY1imsd7c/XwQ8Fvhwu/5S4Acz3XFV3Z/kdcBlwCLgQ1V1XZIzgcmqWg1cCFyUZAOwiSZkAF4HHAS8I8k72rblVXXHTOuSJA0mVVs9yGg6JJNVNTFd23wwMTFRk5OToy5DkuaVJOv6/Z8/yDWQnZM8vueDDgR2ns3iJEnzzyB3Yf0BcEWSG4EAB9De1SRJWri2GSBJdqC58+lg4Ilt8/V+50KStM1TWFX1APBHVXVvVX2tfRkekqSBroFcnuTNSfZLsvuW19ArkySNtUGugbyk/fnanrYCHt+nryRpgZg2QKrqwLkoRJI0vww0F1aSJ9FMub7Tlraq+tthFSVJGn/TBkiS04CjaALk0zTP7/giYIBI0gI2yEX0E4Gjgdur6hXAU2hu7ZUkLWCDBMhP29t570/yq8AdPHQWXUnSAjTINZDJdvbbvwLWAZtpZseVJC1gg9yF9Zp28f1JPgP8alV9fbhlSZLG3SAX0S8CvgBcWVXXD78kSdJ8MMg1kA8B+wB/luTGJB9P8oYh1yVJGnODnML6XJIvAM8AngP8Z+BQ4L1Drk2SNMYGOYW1lub5H1cBVwLP8Ml/kqRBTmF9HbgPeBLwZOBJSR451KokSWNvkFNYbwRI8hjgPwF/TfOM9B2HWpkkaawNcgrrdcCzgacD36O5qH7lcMuSJI27Qb5IuBPwp8C6qrp/yPVIkuaJaa+BVNW7gV8B/iNAkiVJnOJdkha4aQOknY33LcBb26ZfAT48zKIkSeNvkLuwXgi8APhXgKr6PvCYYRYlSRp/gwTIfVVVNI+xJcnOwy1JkjQfDBIgH03yAWDXJK8GLqeZmVeStIBt8y6sJAEuAZ4I/AR4AvCOqlozB7VJksbYNgOkqirJp6vqMMDQkCQ9aJBTWNckecbQK5EkzSuDfJHwSOB3k9xEcydWaA5OnjzUyiRJY22QAHnu0KuQJM07g3wT/aZ+r9nYeZLjktyQZEOSU/ts3zHJJe32LyVZ1rPtrW37DUkMOUmaY4NcAxmKJIuA9wHHA4cAL01yyJRurwTurKqDgPOAc9r3HgKcRPNgq+OAv2g/T5I0R0YWIMARwIaqurGq7gMuBlZM6bMCWNUufww4ur21eAVwcVXdW1XfBTa0nydJmiMDBUiSA5Ic0y4/sn02yEztC9zcs35L29a3TzsT8F3AHgO+d0vtpySZTDK5cePGWShbkgSDTab4apq//j/QNi0F/nGYRc2mqrqgqiaqamLJkiWjLkeSHjYGOQJ5LfAsmm+iU1Xrgb1mYd+3Avv1rC9t2/r2SbIY2AX40YDvlSQN0SABcm97jQJ48D/ymoV9Xw0cnOTAJI+guSi+ekqf1cDKdvlE4LPtxI6rgZPau7QOBA4GvjwLNUmSBjTI90A+n+S/A49McizwGuBTM91xVd3fPi73MmAR8KGqui7JmcBkVa0GLgQuSrIB2EQTMrT9Pgp8E7gfeG1V/XymNUmSBpfmD/ptdEh2oLmddjnNt9AvAz5Y071xDE1MTNTk5OSoy5CkeSXJuqqamNo+7RFIVT1AM327U7hLkh40bYAk+Qa/fM3jLmASOKuqfjSMwiRJ422QayD/BPwc+Ei7fhLwKOB24G+A5w+lMknSWBskQI6pqqf1rH8jyTVV9bQkJw+rMEnSeBvkNt5FSR6cJqR9NsiWeafuH0pVkqSxN8gRyKuADyV5NM1dWD8BXpVkZ+CPh1mcJGl8DXIX1tXAYUl2adfv6tn80WEVJkkab4McgZDk39NMnb5TMxkuVNWZQ6xLkjTmBplM8f3AS4DX05zC+g/AAUOuS5I05ga5iP5vqurlNA92OgN4JvDrwy1LkjTuBgmQe9qfdyd5HPAzYJ/hlSRJmg8GuQbyqSS7Au8CrqH5VrrTmkjSArfNAGknUlxbVT8GPp7kfwM7TbkTS5K0AG3zFFY7keL7etbvNTwkSTDYNZC1SV6cLffvSpLEYAHy+8A/APcl+UmS/5fkJ0OuS5I05gb5Jvpj5qIQSdL8MsgXCZPk5CT/o13fr3dyRUnSwjTIKay/oPny4Mva9c30XFiXJC1Mg3wP5Mj22R9fAaiqO5M8Ysh1SZLG3CBHID9Lsoj2sbZJlgAPDLUqSdLYGyRAzgc+AeyV5H8CXwT+11CrkiSNvUHuwvq7JOuAo2lm4z2hqr419MokSWNt2gBJcj5wcVV54VyS9KBBTmGtA96e5DtJ3p1kYthFSZLG37QBUlWrqup5wDOAG4BzkqwfemWSpLE2yBHIFgcBT6R5GuH1wylHkjRfDPJN9HPbI44zgWuBiap6/tArkySNtUG+SPgd4JlV9cNhFyNJmj8GuY33A0l2a+e/2qmn/QtDrUySNNYGOYX1KuALwGXAGe3P02ey0yS7J1mTZH37c7et9FvZ9lmfZGXb9qgklya5Psl1Sc6eSS2SpG4GuYj+Bpo7sG6qqucATwV+PMP9nkrzqNyDgbXt+kMk2R04DTgSOAI4rSdo3l1VT2xreVaS42dYjyRpOw0SIPdU1T0ASXasquuBJ8xwvyuAVe3yKuCEPn2eC6ypqk1VdSewBjiuqu6uqs8BVNV9wDXA0hnWI0naToNcRL8lya7APwJrktwJ3DTD/e5dVbe1y7cDe/fpsy9wc28dbduD2rqeD7x3hvVIkrbTIBfRX9gunp7kc8AuwGeme1+Sy4HH9tn0timfX0lqgFqnfv5i4O+B86vqxm30OwU4BWD//fff3t1IkrZikCOQB1XV57ej7zFb25bkB0n2qarbkuwD3NGn263AUT3rS4EretYvANZX1XumqeOCti8TExPbHVSSpP6255vos2k1sLJdXgl8sk+fy4Dl7S3EuwHL2zaSnEVzJPQHc1CrJKmPUQXI2cCx7Tfcj2nXSTKR5IMAVbUJeCdwdfs6s6o2JVlKcxrsEOCaJF9tbzWWJM2hVC2cszoTExM1OTk56jIkaV5Jsq6qfmkm9lEdgUiS5jkDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTgwQSVInBogkqRMDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTgwQSVInBogkqRMDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTgwQSVInBogkqRMDRJLUiQEiSerEAJEkdWKASJI6MUAkSZ0YIJKkTkYSIEl2T7Imyfr2525b6bey7bM+yco+21cnuXb4FUuSphrVEcipwNqqOhhY264/RJLdgdOAI4EjgNN6gybJi4DNc1OuJGmqUQXICmBVu7wKOKFPn+cCa6pqU1XdCawBjgNI8mjgTcBZc1CrJKmPUQXI3lV1W7t8O7B3nz77Ajf3rN/StgG8E/gT4O7pdpTklCSTSSY3btw4g5IlSb0WD+uDk1wOPLbPprf1rlRVJant+NzDgV+rqjcmWTZd/6q6ALgAYGJiYuD9SJK2bWgBUlXHbG1bkh8k2aeqbkuyD3BHn263Akf1rC8FrgCeCUwk+R5N/XsluaKqjkKSNGdGdQprNbDlrqqVwCf79LkMWJ5kt/bi+XLgsqr6y6p6XFUtA34L+LbhIUlzb1QBcjZwbJL1wDHtOkkmknwQoKo20VzruLp9ndm2SZLGQKoWzmWBiYmJmpycHHUZkjSvJFlXVRNT2/0muiSpEwNEktSJASJJ6sQAkSR1YoBIkjoxQCRJnRggkqRODBBJUicGiCSpEwNEktSJASJJ6sQAkSR1YoBIkjoxQCRJnRggkqRODBBJUicGiCSpEwNEktSJASJJ6sQAkSR1YoBIkjoxQCRJnRggkqRODBBJUiepqlHXMGeSbARuGnUd22lP4IejLmKOOeaFwTHPHwdU1ZKpjQsqQOajJJNVNTHqOuaSY14YHPP85yksSVInBogkqRMDZPxdMOoCRsAxLwyOeZ7zGogkqROPQCRJnRggkqRODJAxkGT3JGuSrG9/7raVfivbPuuTrOyzfXWSa4df8czNZMxJHpXk0iTXJ7kuydlzW/32SXJckhuSbEhyap/tOya5pN3+pSTLera9tW2/Iclz57Lumeg65iTHJlmX5Bvtz9+e69q7mMnvuN2+f5LNSd48VzXPiqryNeIXcC5wart8KnBOnz67Aze2P3drl3fr2f4i4CPAtaMez7DHDDwKeE7b5xHAlcDxox7TVsa5CPgO8Pi21q8Bh0zp8xrg/e3yScAl7fIhbf8dgQPbz1k06jENecxPBR7XLj8JuHXU4xnmeHu2fwz4B+DNox7P9rw8AhkPK4BV7fIq4IQ+fZ4LrKmqTVV1J7AGOA4gyaOBNwFnzUGts6XzmKvq7qr6HEBV3QdcAyydg5q7OALYUFU3trVeTDP2Xr3/Fh8Djk6Stv3iqrq3qr4LbGg/b9x1HnNVfaWqvt+2Xwc8MsmOc1J1dzP5HZPkBOC7NOOdVwyQ8bB3Vd3WLt8O7N2nz77AzT3rt7RtAO8E/gS4e2gVzr6ZjhmAJLsCzwfWDqPIWTDtGHr7VNX9wF3AHgO+dxzNZMy9XgxcU1X3DqnO2dJ5vO0ff28BzpiDOmfd4lEXsFAkuRx4bJ9Nb+tdqapKMvC91UkOB36tqt449bzqqA1rzD2fvxj4e+D8qrqxW5UaR0kOBc4Blo+6liE7HTivqja3ByTzigEyR6rqmK1tS/KDJPtU1W1J9gHu6NPtVuConvWlwBXAM4GJJN+j+X3uleSKqjqKERvimLe4AFhfVe+ZhXKH5VZgv571pW1bvz63tKG4C/CjAd87jmYyZpIsBT4BvLyqvjP8cmdsJuM9EjgxybnArsADSe6pqj8fftmzYNQXYXwVwLt46AXlc/v02Z3mPOlu7eu7wO5T+ixj/lxEn9GYaa73fBzYYdRjmWaci2ku/h/ILy6wHjqlz2t56AXWj7bLh/LQi+g3Mj8uos9kzLu2/V806nHMxXin9DmdeXYRfeQF+Cpozv2uBdYDl/f8JzkBfLCn3+/RXEjdALyiz+fMpwDpPGaav/AK+Bbw1fb1qlGPaRtjfR7wbZo7dd7Wtp0JvKBd3onmDpwNwJeBx/e8923t+25gTO80m80xA28H/rXn9/pVYK9Rj2eYv+Oez5h3AeJUJpKkTrwLS5LUiQEiSerEAJEkdWKASJI6MUAkSZ0YIFIfSc5MstUvQm7H52yepXrek+Tftsuva2d1rSR79vRJkvPbbV9P8rSebX1ncm6/gLqt/V6c5ODZGIMefryNVxqiJJur6tEz/Iw9gEur6jfb9acCd9J8K3+iqn7Ytj8PeD3NdxKOBN5bVUcm2R2YpPmOTQHrgKdX1Z1JvldVy7ax738HnFxVr57JGPTw5BGIFoQkJyf5cpKvJvlAkkVt++Yk57XPFVmbZEnb/jdJTmyXz07yzfav+ne3bcuSfLZtW5tk/7b9wCRXtc+zOGtKDX+Y5Or2PWe0bTunebbJ15Jcm+Qlfcp/MfCZLSvVzFj7vT79VgB/W43/C+zaThOz1ZmcgY3T1HElcEw7/Yb0EAaIHvaS/AbwEuBZVXU48HPgd9vNOwOTVXUo8HngtCnv3QN4Ic3UFE/mF1Pm/xmwqm37O+D8tv29wF9W1WHAbT2fsxw4mGbq78OBp7enpI4Dvl9VT6mqJ9ETFD2eRXPUMJ2tzQq71dliq+oZbVvfOqrqAZpvTz9lgP1rgTFAtBAcDTwduDrJV9v1x7fbHgAuaZc/DPzWlPfeBdwDXJjkRfxiyvxn0jzAC+Cinvc9i2aG4C3tWyxvX1+heX7JE2kC5RvAsUnOSfLsqrqrT/370B4pDNG26rgDeNyQ9695yADRQhCao4XD29cTqur0rfR9yEXBap7dcATNQ4B+h/5HCNv8jJ4a/rinhoOq6sKq+jbwNJr/wM9K8o4+7/0pzVxK09narLDTzhY7TR07tTVID2GAaCFYSzNl9l7w4PPYD2i37QCc2C6/DPhi7xvbB/7sUlWfBt7IL07l/B+aWVWhOR12Zbv8L1Pat7gM+L3280iyb5K9kjwOuLuqPkwzQ/HT+GXfAg4aYJyrgZe3d2P9JnBXNQ/tugxYnmS3NM+eX9629Y5zW3X8OnDtAPvXAuOFMT3sVdU3k7wd+OckOwA/o5le+yaamV+PaLffQXOtpNdjgE8m2YnmKOJNbfvrgb9O8oc0p5de0ba/AfhIkrcAn+yp4Z/bazFXtQ8O2gycTBMM70ryQFvXf+kzhEuB3wc+CJDkvwJ/RPOwrq8n+XRVvQr4NM0dWBtoTrW9ot33piTvBK5uP+/Mqto0ZR+H9asjyd7AT6vq9r7/uFrQvI1XC9ps3GY7F5J8EfidqvrxHO/3jcBPqurCudyv5gdPYUnzw38D9h/Bfn8MrBrBfjUPeAQiSerEIxBJUicGiCSpEwNEktSJASJJ6sQAkSR18v8B5G9ua3tgDpcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fTKXJtLJMGDx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}